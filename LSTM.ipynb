{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "# import cairocffi as cairo\n",
    "# import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "run_name, start_epoch, stop_epoch = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S'), 0, 10\n",
    "\n",
    "# Input Parameters\n",
    "img_h = 48\n",
    "img_w = 1000\n",
    "words_per_epoch = 1000\n",
    "val_split = 0.1\n",
    "val_words = int(words_per_epoch * (val_split))\n",
    "print(val_words)\n",
    "# Network parameters\n",
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "minibatch_size = 32\n",
    "\n",
    "input_shape = (img_w, img_h, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 1000, 48, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 1000, 48, 16) 160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 500, 24, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 500, 24, 16)  2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 250, 12, 16)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 250, 192)     0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 250, 32)      6176        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 250, 512)     837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 250, 512)     837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 250, 512)     0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 250, 512)     1574400     add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 250, 512)     1574400     add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 250, 1024)    0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 250, 128)     131200      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 250, 128)     0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,962,896\n",
      "Trainable params: 4,962,896\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act = 'relu'\n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv2')(inner)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2),\n",
    "                    (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = GRU(rnn_size, return_sequences=True,\n",
    "            kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True,\n",
    "             go_backwards=True, kernel_initializer='he_normal',\n",
    "             name='gru1_b')(inner)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "gru_2 = GRU(rnn_size, return_sequences=True,\n",
    "            kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n",
    "             kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = Dense(128, kernel_initializer='he_normal',\n",
    "              name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "Model(inputs=input_data, outputs=y_pred).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='the_labels',\n",
    "               shape=[128], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "# Keras doesn't currently support loss funcs with extra parameters\n",
    "# so CTC loss is implemented in a lambda layer\n",
    "loss_out = Lambda(\n",
    "    ctc_lambda_func, output_shape=(1,),\n",
    "    name='ctc')([y_pred, labels, input_length, label_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipnorm seems to speeds up convergence\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length],\n",
    "              outputs=loss_out)\n",
    "\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captures output of softmax so we can decode the output during visualization\n",
    "test_func = K.function([input_data], [y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'the_input_8:0' shape=(?, 1000, 48, 1) dtype=float32>,\n",
       " <tf.Tensor 'the_labels_6:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'input_length_6:0' shape=(?, 1) dtype=int64>,\n",
       " <tf.Tensor 'label_length_6:0' shape=(?, 1) dtype=int64>]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 1 arrays: [array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-b46d49bfdbbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     epochs=1)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     validation_data=data_container.test_set,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     validation_steps=val_words // minibatch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/muteferrika/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/muteferrika/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/muteferrika/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/muteferrika/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/muteferrika/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/muteferrika/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 1 arrays: [array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0...."
     ]
    }
   ],
   "source": [
    "gen = dataGenerator(data_container.training_set, 128)\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=gen,\n",
    "    steps_per_epoch=128,\n",
    "    epochs=1)\n",
    "#     validation_data=data_container.test_set,\n",
    "#     validation_steps=val_words // minibatch_size,\n",
    "#     callbacks=[viz_cb, img_gen],\n",
    "#     initial_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(pathes, batch_size):\n",
    "\n",
    "    while True: #generators for keras must be infinite\n",
    "        for path in pathes:\n",
    "            x_train, y_train = path\n",
    "\n",
    "            totalSamps = x_train.shape[0]\n",
    "            batches = totalSamps // batch_size\n",
    "\n",
    "            if totalSamps % batch_size > 0:\n",
    "                batches+=1\n",
    "\n",
    "            for batch in range(batches):\n",
    "                section = slice(batch*batch_size,(batch+1)*batch_size)\n",
    "                yield (x_train[section], y_train[section])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from library import lineest, util\n",
    "from collections import Counter\n",
    "import click\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import bidi.algorithm as bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroundTruthContainer(object):\n",
    "    \"\"\"\n",
    "    Container for ground truth used during training.\n",
    "    Attributes:\n",
    "        training_set (list): List of tuples (image, text) for training\n",
    "        test_set (list): List of tuples (image, text) for testing\n",
    "        alphabet (str): Sorted string of all codepoint found in the ground\n",
    "                        truth\n",
    "    \"\"\"\n",
    "    def __init__(self, images=None, split=lambda x: os.path.splitext(x)[0],\n",
    "                 suffix='.gt.txt', normalization=None, reorder=True,\n",
    "                 partition=0.9, pad=16, directory=''):\n",
    "        \"\"\"\n",
    "        Reads a list of image-text pairs and creates a ground truth set.\n",
    "        Args:\n",
    "            images (list): List of file paths of line images\n",
    "            split (func): Function for generating the base name without\n",
    "                          extensions from paths\n",
    "            suffix (str): Suffix to attach to image base name for text\n",
    "                          retrieval\n",
    "            normalization (str): Unicode normalization for gt\n",
    "            reorder (bool): Whether to rearrange code points in \"display\"/LTR\n",
    "                            order\n",
    "            partition (float): Ground truth data partition ratio between\n",
    "                               train/test set.\n",
    "            pad (int): Padding to add to images left and right\n",
    "        \"\"\"\n",
    "        self.lnorm = lineest.CenterNormalizer()\n",
    "        self.training_set = []\n",
    "        self.test_set = []\n",
    "        self.training_alphabet = Counter()\n",
    "        self.test_alphabet = Counter()\n",
    "\n",
    "        if not images:\n",
    "            return\n",
    "        for line in images:\n",
    "            self.add(line, split, suffix, normalization, reorder, pad, directory=directory)\n",
    "\n",
    "        self.repartition(partition)\n",
    "\n",
    "    def add(self, image, split=lambda x: os.path.splitext(x)[0],\n",
    "                 suffix='.gt.txt', normalization=None, reorder=True,\n",
    "                 pad=16, directory=''):\n",
    "        \"\"\"\n",
    "        Adds a single image to the training set.\n",
    "        \"\"\"\n",
    "        with click.open_file(directory + split(image) + suffix, 'r', encoding='utf-8') as fp:\n",
    "            gt = fp.read()\n",
    "            if normalization:\n",
    "                gt = unicodedata.normalize(normalization, gt)\n",
    "            if reorder:\n",
    "                gt = bd.get_display(gt)\n",
    "\n",
    "            im = Image.open(image)\n",
    "            im = util.dewarp(self.lnorm, im)\n",
    "            im = util.pil2array(im)\n",
    "            im = lineest.prepare_line(im, pad)\n",
    "            self.training_set.append((im, gt))\n",
    "\n",
    "    def repartition(self, partition=0.9):\n",
    "        \"\"\"\n",
    "        Repartitions the training/test sets.\n",
    "        Args:\n",
    "            partition (float): Ground truth data partition ratio between\n",
    "                               training/test sets.\n",
    "        \"\"\"\n",
    "        self.training_set = self.training_set + self.test_set\n",
    "        idx = np.random.choice(len(self.training_set), int(len(self.training_set) * partition), replace=False)\n",
    "        tmp_set = [self.training_set[x] for x in idx]\n",
    "        [self.training_set.pop(x) for x in sorted(idx, reverse=True)]\n",
    "        self.test_set = self.training_set\n",
    "        self.training_set = tmp_set\n",
    "\n",
    "        self.training_alphabet = Counter(''.join(t for _, t in self.training_set))\n",
    "        self.test_alphabet = Counter(''.join(t for _, t in self.test_set))\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Samples a line image-text pair from the training set.\n",
    "        Returns:\n",
    "            A tuple (line, text) with line being a numpy.array run through\n",
    "            kraken.lib.lstm.prepare_line.\n",
    "        \"\"\"\n",
    "        return self.training_set[np.random.choice(len(self.training_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/muteferrika/lib/python3.6/site-packages/scipy/ndimage/interpolation.py:450: UserWarning: The behaviour of affine_transform with a one-dimensional array supplied for the matrix parameter has changed in scipy 0.18.0.\n",
      "  \"The behaviour of affine_transform with a one-dimensional \"\n"
     ]
    }
   ],
   "source": [
    "dataset = np.genfromtxt('data/manifest.txt', delimiter='\\n', dtype=str)\n",
    "print(dataset.shape)\n",
    "data_container = GroundTruthContainer(images=list(dataset), directory='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [data_container.training_set[sh][1] for sh in range(len(data_container.training_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(list(i))for i in shapes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X = np.asarray([data_container.training_set[i][0] for i in range(len(data_container.training_set))])\n",
    "training_y = np.asarray([list(data_container.training_set[i][1]) for i in range(len(data_container.training_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
